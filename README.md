# ğŸ§  **Conversational RAG PDF Chatbot**  
*A Streamlit app that lets you upload PDFs and chat with them using a Retrieval-Augmented Generation (RAG) pipeline â€” with full chat history memory.*


## âœ¨ Features

- ğŸ“„ **Upload Multiple PDFs** â€“ Ask questions across one or more documents at once.
- ğŸ” **Retrieval-Augmented Generation (RAG)** â€“ Combines local document search with LLM reasoning.
- ğŸ’¬ **Persistent Chat History** â€“ Keeps track of past conversation context by session ID.
- âš¡ **Plug-and-Play LLM** â€“ Uses [Groqâ€™s](https://groq.com/) ultra-fast `llama-3.3-70b-versatile` model.
- ğŸ§© **Custom Embeddings** â€“ Uses Hugging Face `all-MiniLM-L6-v2` embeddings.
- ğŸ–¥ï¸ **Simple UI** â€“ Streamlit app with clean user inputs and outputs.

---

## ğŸ—ï¸ Tech Stack

- [**Streamlit**](https://streamlit.io/) â€“ web app framework  
- [**LangChain**](https://www.langchain.com/) â€“ RAG pipeline and message history  
- [**Chroma**](https://www.trychroma.com/) â€“ vector database for document retrieval  
- [**Hugging Face**](https://huggingface.co/) â€“ embeddings (`all-MiniLM-L6-v2`)  
- [**Groq API**](https://groq.com/) â€“ LLM inference  
- Python 3.8+  

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Clone the Repository
- git clone https://github.com/your-username/conversational-rag-pdf-chatbot.git
- cd conversational-rag-pdf-chatbot


### 2ï¸âƒ£ Create & Activate Virtual Environment
- python3 -m venv venv
- source venv/bin/activate   # On Mac/Linux
- venv\Scripts\activate      # On Windows


### 3ï¸âƒ£ Install Requirements
- pip install -r requirements.txt


### 4ï¸âƒ£ Set Up Environment Variables
- HF_TOKEN=your_huggingface_api_token
- GROQ_API_KEY=your_groq_api_key


### 5ï¸âƒ£ Run the App
- streamlit run app.py


## ğŸ§© How It Works

- PDF Loading â†’ Uses PyPDFLoader to extract text.
- Text Splitting â†’ Chunks documents with RecursiveCharacterTextSplitter.
- Vector Store Creation â†’ Stores embeddings in Chroma.
- History-Aware Retriever â†’ Reformulates user questions using previous chat context.
- LLM Answering â†’ Sends retrieved context + question to Groqâ€™s llama-3.3-70b-versatile.
- Session Memory â†’ ChatMessageHistory keeps per-session conversations.

## ğŸ–¥ï¸ Demo
- ![App Screenshot](/Users/pahul17/Documents/End-End-Projects/4 - RAG Q&A With chat History/images/demo.png)

## âš¡ Future Enhancements

- Support for multiple LLM providers (OpenAI, Anthropic).
- Add document type detection (Word, CSV, HTML).
- Option to download chat history as PDF/CSV.
- Deploy on Streamlit Cloud / Hugging Face Spaces.


## ğŸ’¡ Tips to Customize
- Replace `Conversational RAG PDF Chatbot` with your final repo name.  
- Add a **demo GIF** or Streamlit app link if you deploy it.  
- Update the **Future Enhancements** list with your personal roadmap.  
- Add badges (deployment, Python version) if you want a more polished look.

